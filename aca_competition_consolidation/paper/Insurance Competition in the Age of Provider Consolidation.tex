\documentclass[12pt,letterpaper]{article}
\usepackage[margin=1in]{geometry}
\usepackage[english]{babel}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb} 
\usepackage[retainorgcmds]{IEEEtrantools}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{subfig}
\usepackage{kpfonts}    % for nice fonts
\usepackage{microtype} 
\usepackage{booktabs}   % for nice tables
\usepackage{bm}         % for bold math
\usepackage{listings}   % for inserting code
\usepackage{verbatim}   % useful for program listings
\usepackage{color}  
\usepackage[colorlinks=true, citecolor=black]{hyperref}
% use for hypertext
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{natbib}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage{caption}
\usepackage{float}
\newfloat{Equation}{htbp}{loa}
\usepackage{geometry}
\usepackage[compact]{titlesec}
\usepackage{makecell}
\usepackage{pdflscape}
\usepackage{chngcntr}


\setcounter{MaxMatrixCols}{10}
\geometry{letterpaper,tmargin=1in,bmargin=1in,lmargin=1.0in,rmargin=1.0in}
\hypersetup{urlcolor=black,citecolor=black,colorlinks=true,linkcolor=black,raiselinks=false,pdfstartview={XYZ null null 1.20}}
\linespread{1.5}
\setlength{\footnotesep}{0.7\baselineskip}
\setlength{\parindent}{24pt}

\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{L}[1]{>{\hangindent=1em \raggedright \let\newline\\\arraybackslash}p{#1}}
%\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
%\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}


\newenvironment{nenumerate}{\enumerate\addtolength{\itemsep}{-3pt}}{\endenumerate}


\titlespacing{\section}{0pt}{10pt}{5pt}
\titlespacing{\subsection}{2pt}{8pt}{4pt}
\titlespacing{\subsubsection}{0pt}{10pt}{3pt}

\newtheorem{result}{Prediction}
\newtheorem{claim}{Claim}
\newtheorem{assumption}{Assumption}

\graphicspath{{"./graphs/"}{"./maps/"}}
\widowpenalty=10000

\begin{document}
\title{\vspace{-.8cm}Insurer competition in the age of provider consolidation:
The relationship between hospital and insurance competition in the ACA individual market\thanks{I thank Professors Colleen M. Grogan, Kotaro Yoshida and Victor O. Lima for all their guidance over the course of this project. I thank the Dean's Fund and the Becker Friedman Institute for sponsoring this project.}}
\date{\vspace{.3cm}\today}
\author{\begin{tabular}{c}
 Jacob Toner Gosselin\end{tabular}}
\maketitle
\normalsize


\begin{abstract}\onehalfspacing{
\noindent This paper investigates the impact of hospital competition (or lack thereof) on insurer participation in the ACA's individual market. Using public data from CMS, and private data from the American Hospital Association (AHA), I construct an HHI measurement for hospital and insurer markets at the county-level in 34 of the 36 states using federally facilitated marketplaces, across 2015 and 2016 (hospital HHI is lagged by one year). I fit a linear model on 2070 counties across two years in these states, controlling for county-level covariates and fixed effects for year and "rating area" (a geographic designation created by the ACA,  which typically amounts to a collection of counties), and estimate my parameters using OLS. I find higher hospital HHI levels are associated with higher insurer HHI levels at a coefficient of .042, log linearized. While the coefficient is small, it is highly significant and reasonably robust given my stringent fixed effects. I contribute to the existing literature by focusing on insurer competition rather than premium price as my primary outcome, leveraging "rating areas" for better model specification, and outlining a novel approach to hospital market HHI construction using hospital "radii" rather than pre-existing geographic bounds. }\end{abstract}

\DeclareGraphicsExtensions{.pdf,.tif}

\thispagestyle{empty}

\newpage \setcounter{page}{1}

\section*{Introduction}
Since the Affordable Care Act (ACA) came into effect in 2014, the state of its exchanges (regulated markets that allow individuals to buy coverage separate from their employer) has been closely studied as an indicator of the law's success.  Though these exchanges represent only a fraction of the insured population (roughly 4\%, or 9 million individuals nationwide), they've adopted outsized political significance. In the past few years, diminishing competition in exchanges nationwide has sparked panic about these markets' sustainability \citep{cox_analysis_2015}. 

Qualitative studies have pointed to competition among healthcare providers as "essential to a robust and competitive insurer market" \citep{morrisey_five-state_2017}. Most quantitative work, however, has either ignored provider competition when looking at diminishing insurer choice,  or focused on how provider competition relates to insurer premiums, rather than participation, in ACA exchanges.

This paper seeks to fill this hole, by answering two questions: 1) How is competition between short term general hospitals related to competition on ACA exchanges, and 2) How robust is this relationship to regional variation and model specification? It adds to the literature by documenting a novel method of constructing hospital market HHI at the county-level and by exploiting a unique feature of ACA markets, rating areas, to control for geographic fixed effects and mitigate the risk of omitted variable bias. 

It is organized as follows: Section 1 reviews the relevant research on market dynamics in the ACA, and explain how my work fits into this existing literature; Section 2 goes over my data sources and HHI construction; Section 3 explains my model; Section 4 reviews my results; Section 5 explains the limitations of my model; Section 6 and 7 discuss my results and their policy implications; and Section 8 outlines potential directions for future work. 

\section{Background}
By 2016, the third year of ACA exchanges' operation, it was clear that maintaining a healthy level of competition in these markets posed a greater challenge than anticipated. While the drop off in market participation in the past four years can be in part attributed to the law's precarious future under the Trump Administration, even before the 2016 election warning signs had emerged: between 2015 and 2016, the percent of enrollees in the individual market with three or more insurers to choose from fell from 91\% to 85\%, and the average "benchmark" premium rose by 4.4\% \citep{cox_analysis_2015}.

In response to these concerning trends, the Brookings Institution's Center for Health policy commissioned a field study across multiple state exchanges in 2016 \citep{morrisey_five-state_2017}. Researchers interviewed stakeholders, i.e. insurers, consumer groups, and state regulators, in California, Michigan, Florida, North Carolina, and Texas. They walked away with four main conclusions: (1) health insurance markets are local, meaning the success or failure of insurers, even national ones, are determined by local factors; (2) higher than expected claims cost were the source of much of the early turmoil in in insurance markets; (3) there has been a substantial shift towards narrower networks of healthcare providers, as a way of forcing hospitals to compete for enrollees by reducing reimbursement rates; and (4) Hospital and physician competition is "essential" for a robust and competitive insurer market.

These conclusions were prescient, and confirmed by quantitative work in the years following. Early studies of the ACA exchange confirmed that insurance plans on the ACA exchange often had "narrow networks", i.e. they offered a less broad network of healthcare providers to consumers than the typical insurance plan \citep{haeder_narrow_2015}. This shift was predictable given ACA regulations, which prevented insurers from competing over enrollees as they had in the past,(through practices like denial of coverage and medical underwriting). Instead, insurers on ACA exchanges competed over providers; they narrowed their networks, and forced hospitals and doctors to offer cheaper reimbursement rates to have their enrollees as patients. In practice, this approach produced promising results: a paper by Harvard and Northwestern researchers found that narrow network plans were 16\% cheaper than their broad network counterparts, and that these plans reduced medical costs \citep{dafny_narrow_2017}. 

Soon after, \citet{griffith_diminishing_2018}, using four years of marketplace data, analyzed factors correlated with competition on the ACA exchange. These factors were both state based and county based. Using multivariate and bivariate regressions, they concluded that rurality, demographics, health spending, and state policy environment had a significant impact on the number of insurers participating in a given rating area. In other words, they found that health insurance markets are local. 

While these characteristics of ACA markets imply a link between provider competition and insurer competition, this relationship has only just begun to be examined. \citet{scheffler_consolidation_2018} looked at the impact provider consolidation had on premiums in California's state run ACA exchange. Using a multivariate model, they regressed the Herfindahl-Hirschman Index (HHI) of short term general hospitals (measuring horizontal consolidation), the percent of physicians contracting with hospitals (measuring vertical consolidation) and the HHI of insurers in a given marketplace on the benchmark premium (all independent variables were lagged by a year), across California's 19 rating areas, over 3 years. They found that a 10\% increase in hospital HHI was associated with a 1.8\% increase in marketplace premiums, while a 10\% increase in insurer HHI was associated with a 2\% increase in premiums.

\citet{boozary_association_2019} expanded the work of \citet{scheffler_consolidation_2018} to a nationwide sample, producing similar results: rating areas with the highest levels of hospital market concentration had annual premiums that were, on average, 5 percent higher than those in the least concentrated areas. They concluded that the "likely explanation for higher premiums being found in areas of greater hospital concentration (and, indeed, the one consistent with prior literature) is related to market power and the ability to negotiate higher prices from insurers and other payers in these areas." \citep{boozary_association_2019}. 

Both papers provide compelling evidence that concentrated hospital markets result in higher negotiated rates for insurers, which are then passed off to consumers in the form of higher premiums. However, they are limited in two respects: 1) their models are specified at the "rating-area" level, and 2) premiums may not be the best reflection of consumer experience on ACA.

In regards to (1), geographic "rating-areas" are intra-state regions (typically collections of counties) within which insurers must set premiums uniformly on ACA exchanges. However, insurers are allowed to pick and choose which counties within a rating area they want to offer their plans. As \citet{fang_why_2020} observed, it is quite common for insurers to selectively enter counties within a rating area. Their research found that provider set up cost is one of the main mechanisms driving this pattern (insurers with previously established Medicare Advantage plans within a county were more likely to enter it, as they had already established a suitable provider,network).

While county-level variation isn't particularly important when looking at premiums as a primary outcome (especially benchmark premiums, as both \citet{scheffler_consolidation_2018} and \citet{boozary_association_2019} did), when looking at insurer participation it is necessary. Moreover, variation in insurer participation across rating areas provides a powerful tool for model specification; controlling for rating-area fixed effects greatly mitigates the risk of omitted-variable bias.

In regards to (2), while prices are obviously a primary indicator of consumer experience, they are not the only metric to measure market health. This is especially true for ACA exchanges, a heavily subsidized market where the vast majority of consumers pay for their plans as a percent of income, and are therefore shielded from price hikes. Choice and competition (i.e. HHI) are therefore equally worthwhile metrics to consider as outcomes. In addition,insurer competition can also influence premium prices, as found by \citet{scheffler_consolidation_2018}.  Thus, if hospital competition influences insurer participation, it can have a two-fold impact on premium prices: first raising premiums due to higher reimbursement rates, then raising premiums due to reduced insurer competition. 

\section{Data Construction}
To measure insurer HHI, I pulled issuer-level enrollment data from the Center for Medicare and Medicaid Services (CMS). This enrollment data is for all federally facilitated marketplaces (FFMs), i.e. marketplaces run by the federal government. It includes 36 states. I removed Alaska and Nebraska from my analysis, as their rating areas are not based on county borders, making it near impossible to control for county-level variables. The enrollment data also withholds information on counties with 10 or less enrollees in a given plan, due to privacy concerns. Moreover, 147 counties are in single county rating-areas, and are thus excluded from my main model which controls for rating-area fixed effects (they are included in alternative specifications). In total, we are left with 2223 counties across two years (see maps in appendix). 

My enrollment data is for 2015 and 2016; these years provide the most stable market conditions, as insurers already had a year of experience in ACA exchanges (2014) and President Trump was not yet elected (2017-2018). They also provide a good spread of HHI's in both years, (see \hyperref[Figure 1]{Figure 1} below). I constructed my HHI measurement by calculating market share for each insurer in a given county as a percent of total enrollees, and summing the results. 

\begin{figure}[!h]
\begin{center}
\caption{Insurer HHI Distribution}\label{Figure 1}
\includegraphics[height=4in,angle=0]{hist_year_insurerhhi.png}
\end{center}
\end{figure}

The rest of my variables are lagged by one year, since insurers decide on participating in a given county before November of the previous year. To measure provider competition, I used data from the American Hospital Association (AHA) Annual Survey on short term general care hospitals in 2014 and 2015. I use short term general care hospitals as this is the most common type of hospital nationwide, and the most relevant for insurers building provider networks on the ACA exchange (long term care facilities are usually used by Medicare or Medicaid enrollees). This is in line with the approach of \citet{scheffler_consolidation_2018}.  

\begin{figure}[!ht]
\begin{center}
\caption{Hospital HHI Distribution}\label{Figure 2}
\includegraphics[height=4in,angle=0]{hist_year_hospitalhhi.png}
\end{center}
\end{figure}

While \citet{scheffler_consolidation_2018} and \citet{boozary_association_2019} constructed hospital HHI measurements using "rating-area" boundaries, I had to specify a county measure that allowed for intra rating area variation. I chose not to use county boundaries, since they vary a great deal and can be too restrictive (many counties did not have a short-term hospital within their boundaries). Instead, I used the work of \citet{gresenz_updated_2004}, who found the "75 percent radii" for urban and rural hospitals, i.e. the boundary within which 75 percent of a hospital's admitted patients lived.  I draw radii around each of my hospitals (27.4 miles for hospitals in metro counties, 43.6 miles for hospitals in non-metro counties), and if the radius includes the centroid of a given county, I consider it part of the county's hospital market (a more extensive description of this approach, along with robustness checks for radii, can be found in the appendix). From their, I construct hospital HHI in the typical fashion, using annual admissions as a measure of market share (the remaining 109 counties with no hospitals in their market are given an HHI of 10000; I also include a dummy variable for these "empty counties" in my model).  Again, the spread of HHIs is conducive to my analysis (see \hyperref[Figure 2]{Figure 2}). 

I control for all variables found to be significant in \citet{griffith_diminishing_2018}, and add a few controls of my own for good measure (see \hyperref[Table 1]{Table 1}.  My main model controls for rating area and year fixed effects, and therefore does not include any state-level covariates.  At the county level, I control for population demographics, poverty rate, and mortality rate using data from the Census Bureau's American Community Survey. I control for rurality using the 2013 Rural-Urban Continuum Codes (RUCC) assigned by the US Department of Agriculture Economic Research Service. I control for Medicare spending per capita using data from CMS.  I do specify an additional model with no place-based fixed effects, and in this model I control for state policy environment using data from the National Bureau of State Legislatures (NBSL), Medicaid expansion status using data from the Kaiser Family Foundation (KFF), and average Medical Loss Ratio (MLR) rebate per capita using data from CMS (these are rebates paid by insurers when their medical claims cost is too low). 

\vspace{1cm}

\begin{table}[H]
\caption{Control variables} \label{Table 1}
\centering
\begin{tabular}{l l l}
\toprule
\textbf{Variables} & \textbf{Geographic Level} & \textbf{Source}\\
\midrule
State Policy Environment & State & NBSL \\
Medicaid Expansion Status & State & KFF \\
Average MLR Rebate & State & CMS \\
Insurer HHI & County & CMS \\
Hospital HHI & County & AHA \\
Population Demographics & County & Census\\
Rurality & County & DOA\\
Medicare Spending & County & CMS \\
\bottomrule
\end{tabular}
\end{table} 

\newpage
\newgeometry{margin=1cm}
\begin{landscape}
\begin{table}[!h]
\scriptsize
	\caption{Summary Statistics}
	\centering
	\input{./tables/summary_stats}
\end{table}
\flushleft \footnotesize{Notes: Table reports variable means and standard deviations. Each observation is a county-year combination (i.e. Cook County in 2015). Counties in single-county rating areas are excluded.}
\end{landscape}
\restoregeometry

\section{Model}

I estimate the following ordinary least squares regression, with one observation per county-year combination (i.e. Cook County in 2015).
\\
\begingroup
\captionof{Equation}{Main model}
\vspace{-1.5cm}
\begin{equation}
\makebox[\textwidth]{%
$\begin{aligned}
Y_{i,t} = \beta_0 + \beta_1HospHHI_{i,t-1} + \beta_2(HospHHI_{i,t-1} * \tau_t) +
\lambda\textbf{X}_{i,t-1} + RA_i + \tau_t + (RA_i * \tau_t) + \epsilon_{i,t} \notag \end{aligned}$}
\end{equation} 
\endgroup

$Y_{i,t}$ is insurer HHI (logged) in county $i$ in year $t$. $HospHHI_{i, t-1}$ is hospital HHI (logged) in county $i$ in year $t-1$ (as mentioned before, I lag my variable of interest and county controls by one year). $\textbf{X}_{i, t-1}$ is a vector of controls for county $i$ at time $t-1$ (see Table 1; this vector includes a binary for if the county has no hospitals in its market, which, as mentioned above, only occurs in 4.7\% of counties). $\tau_t$ and $RA_i$ represent time and place fixed effects, i.e. controls for year (in this case a binary variable that is 0 in 2015 and 1 in 2016) and rating area. I also include interaction terms between $RA_i$ and $\tau_t$, and an interaction term, $HospHHI_{i,t-1} * \tau_t$, which captures how logged hospital HHI's impact changes year to year. Thus, $\beta_1$ represents the percent increase in insurer HHI associated with a 1 percent increase in hospital HHI, controlling for county level covariates, empty hospital markets, year and rating area fixed effects, and year*rating area interaction terms, while $\beta_2$ represents the change in that association between 2015 and 2016.

I also specify two variations of my main model: one in line with the findings of \citet{boozary_association_2019}, and one in line with the findings of \citet{griffith_diminishing_2018}. In the former, I replace my rating area level fixed effects ($RA_i$) with state level fixed effects ($ST_i$). I still cluster my standard errors at the rating area level. This is identical to the model used in \citet{boozary_association_2019}, the difference being how I define my dependent variable (insurer HHI) and my variable of interest (hospital HHI).   
\\
\begingroup
\captionof{Equation}{\citet{boozary_association_2019}}
\vspace{-1.5cm}
\begin{equation}
\makebox[\textwidth]{%
$\begin{aligned}
Y_{i,t} = \beta_0 + \beta_1HospHHI_{i,t-1} + \beta_2(HospHHI_{i,t-1} * \tau_t) +
\lambda\textbf{X}_{i,t-1} + ST_i + \tau_t + (ST_i * \tau_t) + \epsilon_{i,t} \notag \end{aligned}$}
\end{equation} 
\endgroup

In the latter, I drop my place-based fixed effects altogether and instead add a vector of state level covariates in line with \citet{griffith_diminishing_2018} ($\textbf{Z}_{i, t-1}$). 
\\
\begingroup
\captionof{Equation}{\citet{griffith_diminishing_2018}}
\vspace{-1.5cm}
\begin{equation}
\makebox[\textwidth]{%
$\begin{aligned}
Y_{i,t} = \beta_0 + \beta_1HospHHI_{i,t-1} + \beta_2(HospHHI_{i,t-1} * \tau_t) +
\lambda\textbf{X}_{i,t-1} + \zeta\textbf{Z}_{i,t-1} + \tau_t + \epsilon_{i,t} \notag \end{aligned}$}
\end{equation} 
\endgroup

These models offer more variation for OLS to exploit (we can now make comparisons across rating areas, rather than just within them). It also allows us to incorporate the aforementioned 147 counties in single county rating areas. On the other hand, the risk of omitted variable bias is higher. 

I cluster my standard errors at the rating-area level to account for within-rating area correlation in all three models.

\section{Results}

I fit all three models on my overall dataset in Table 3, and fit my main model on subsets of the data by region and rurality in Table 4 and Table 5 respectively. All coefficients of interest are the result of a log to log comparison, so they can be interpreted as a percent to percent relationship. 

My overall coefficient of interest in my main model is .042; in other words, a 10\% increase in hospital HHI is associated with a .42\% increase in insurer HHI in my combined dataset. In my alternative models (\citet{boozary_association_2019} and \citet{griffith_diminishing_2018}) my coefficients are .045 and .017, respectively. My coefficient of interest is significant at $p<.01$ except in \citet{griffith_diminishing_2018}, which isn't too concerning; the fixed effects in my main model and \citet{boozary_association_2019} make their estimates much more trustworthy. Going forward I will only consider my main model, as it appears best specified (it has the most rigorous controls, and therefore the lowest likelihood of omitted variable bias).

While my coefficients are small, the narrow distribution of insurer HHI (see Figure 1) implies humble coefficients across the board: there simply isn't much variation to be explained, especially when controlling for time and place-based fixed effects (95\% of logged insurer HHI is between [8.20, 9.02]; to put that another way, 60.90\% of counties across my two years of data had 3 or less insurers in their market). This trend carries over to my control variables: all county level covariates are insignificant in my main model except poverty rate, with a coefficient of .0017, and rurality (measured by RUCC) with a coefficient of .013. 

\begin{table}[!h]
\centering
\caption{Main results}
\input{./tables/main_results}
\end{table}

Exponentiating my coefficients, we see that a 1-point increase in the 9-point RUCC scale is associated with only a 1.3\% increase in logged insurer HHI; thus, according to our model, a 1 point increase in RUCC and a 31\% increase in hospital HHI are associated with the same (OLS estimated) level of impact on insurer HHI. While such extreme increases in HHI might seem unrealistic in most market settings, my constructed county hospital markets are so sparse that these sorts of increases are pretty conceivable. 55.9\% of counties across my two years of data have five or fewer hospitals in their market, and between 2014 and 2015, 46 counties saw an 31\% or greater increase in hospital HHI.

To see if the association between insurer and hospital HHI varies by region or rurality, I fit my main model on subsets of the data by both categories (see Table 4 and Table 5). My OLS estimates of my coefficient of interest lose significance in many cases, which is to be expected given the limited sample size of the subsetted data. But all estimates are tightly clustered around [.03, .05] (the exception being the Northeast region, which is our smallest sample). While my standard errors are too wide to draw any hard conclusions, it doesn't seem that my main effect is being driven by any subset of counties by region or rurality (further confirmation of this can be found in Appendix Table X, where interaction terms are added for each of the subsetted categories; all coefficient estimates lack significance).   
\vspace{1cm}
\begin{table}[!h]
\centering
\caption{Results by rurality (main model)}
\input{./tables/main_results_rucc.tex}
\end{table}

\newgeometry{left=1cm, right=1cm, bottom=1.9cm, top=1.9cm}
\begin{table}
\centering
\caption{Results by region (main model)}
\input{./tables/main_results_region.tex}
\end{table}
\restoregeometry

\section{Limitations}

I am limited to two years of ACA market data (2015 and 2016) and 34 states. The 34 states I studied are primarily rural and southern; most urban coastal states, i.e. New York, California, etc. run their own exchanges. They were also mostly Republican led in 2014 and 2015. My dataset is also limited by time. I chose 2015 and 2016 because I perceive decreasing provider competition to be an existential threat to ACA markets (i.e. not the result of the current instability around the law). My goal was to measure the impact of provider competition in a "stable" ACA market. As a result of these limits on my dataset, the coefficients I observe may not perfectly match the current reality of ACA exchange dynamics. 

Moreover, my hospital HHI measurement doesn't account for vertical consolidation. In the past decade, the percent of primary care physicians working for a hospital system has skyrocketed. This type of market power almost certainly effects contract negotiations between insurers and hospitals, and is not accounted for in my work.

Beyond setting issues, the limitations of my work are those typical of OLS estimates. Variance inflation factors (VIFs) suggest my coefficient for the interaction between hospital HHI and year ($\beta_2$ in my main model) is unstable due to multicollinearity. My main model's residuals fail the Shapiro-Wilk's test of normality, which, though it doesn't undermine the estimate itself, calls into question my p-values. To remedy this concern I "bootstrap" my model, re-fitting it over 5000 samples with replaces, to construct an empirical distribution of my coefficient of interest (this approach is taken from \citet{fox_bootstrapping_2017}). The resulting 99\% confidence interval for $\beta_1$ is (.013, .071); in other words I still reject the null hypothesis at $p<.01$. 

Finally, there is the possibility of endogeneity due to either omitted variable bias or simultaneity. In regards to omitted variable bias, this concern is greatly lessened by my identification strategy (exploiting intra-rating area variation, which controls for time-invariant differences between these collections of counties). In regards to simultaneity, the relationship between marketplace insurers and hospitals implies this shouldn't be a major concern: as mentioned above, marketplace insurers only make up 4\% of insured individuals nationwide, and enrollees produce a minuscule amount of hospital revenue (especially compared to the high-cost patients usually covered by Medicare). However, some marketplace insurers also participate in the employer sponsored market, and enrollees in this market do make up a significant amount of hospital revenue. Thus, there could be simultaneity if ACA exchange firms which also offer in the employer sponsored market make decisions about market entry jointly. 

Besides these aforementioned concerns, my model is fairly rigorous. Cluster-robust standard errors prevent heteroskedasticity/serial correlation concerns (I cluster at the rating-area level). My variance inflation factors are non-concerning for my main effect ($\beta_1$), ruling out multicollinearity. While my residuals fail normality tests, bootstrapping my coefficient of interest confirms my analytic p-values. And the nature of the relationship between hospitals and exchange insurers implies that the effect we see in the data is causal: our hospital HHI is lagged by one year, and since the ACA exchange makes up only a small share of the overall population, it is extremely unlikely hospital competition is influenced by competition on the ACA exchange. The reverse however has already been confirmed in aforementioned qualitative work \citep{morrisey_five-state_2017}.  

\section{Discussion}

The results of my regressions, in combination with the findings of \citet{morrisey_five-state_2017}; that hospital and physician competition are essential to a robust and competitive insurer market under the ACA. The immediate implications of this are two-fold: first, decreasing hospital competition threatens consumer choice in ACA markets, and second, its impact on ACA premiums has likely been underestimated. 

While the first point is self-evident (rising hospital HHI results in higher insurer HHI, which corresponds to less competitive markets and therefore less firms for consumers to choose from), the second is more complicated. Returning to \citet{scheffler_consolidation_2018}, we see that their work concluded that hospital HHI was related to premium price with an elasticity of .182, i.e. a 10\% increase in hospital HHI resulted in a 1.82\% increase in premium price the following year. Scheffler also included insurer HHI in his regressions; he found that insurer HHI was related to premium price with an elasticity of .204. 

While \citet{scheffler_consolidation_2018} work captures the impact hospital consolidation has on premium prices in the short term, i.e. the effect a hospital merger has on premium prices the following year due to higher, it fails to capture the long-term impact of rising hospital HHI on premium prices through insurer HHI. 

To demonstrate, let us consider a hypothetical (AHA data guidelines prevent me from using a specific case). The average monthly benchmark premium in 2015 was \$276 \citep{kff1}, and the average insurer HHI was 6184. Suppose in a given county with this average premium price and average insurer HHI, a hospital merger occurred, which raised hospital HHI by 10\%. By Scheffler's results, this merger would raise monthly premiums by 1.8\%, or \$4.96. By my results, this merger would raise insurer HHI by .42\%, or 26 points. This increase in insurer HHI, by Scheffler's results, would correspond to another rise in premiums the following year (i.e. 2017), of .076\%, 21 cents monthly or \$2.53 annually.

Obviously these numbers aren't precise, and shouldn't be taken as such. \citet{scheffler_consolidation_2018} focused solely on California's state run exchanges, while my work encompasses 34 primarily rural and southern states with federally facilitated marketplaces. The purpose of this exercise though, is to demonstrate that by not accounting for the relationship between competition on ACA exchanges and competition between healthcare providers, researchers underestimate the impact of declining provider competition on premiums.

Moreover, as alluded to in Section 1, it is not clear that premium prices ought to be the focus of research related to the ACA exchanges. Despite some notable exceptions (i.e. the "subsidy cliff"), government subsidies largely shield individuals in the ACA exchange from premium price hikes. What they do not protect against is the lack of choice most consumers face in their county's exchange. As such, even if premiums aren't greatly impacted by the relationship between hospital and insurer competition, that relationship is important in its own right, as it has a more direct impact on the experience of most consumers on ACA exchanges than premiums themselves. 

\section{Policy Implications}

Some of the best policy work addressing ACA exchange failures and hospital consolidation can be found in \citet{berenson_addressing_2015}, \citet{gaynor_making_2017}, and \citet{fiedler_capping_2020}. In this section I draw suggestions from all three. These suggestion can be divided into three categories: (1) regulation reduction, (2) regulation addition, and (3) direct government intervention. 

Starting with (1), \citet{gaynor_making_2017} recommend states remove any willing provider (AWP) laws. These laws require insurers to include any provider in their network who so desires. They have a particularly nasty effect on insurers' ability to compete in the individual market; as mentioned in Section 1, the new regulations brought about by the ACA pushed insurers to narrow their provider networks. This approach forced healthcare providers to compete with one another to be included in a given insurer's network, cutting healthcare costs in the process. AWP laws completely undermine this process. While network adequacy legislation is essential to ensure insurers aren't burdening enrollees with non-existent provider networks, AWP laws are far from necessary to achieve this goal. Rather, their primary effect is to undercut insurers' ability to compete in ACA exchanges, and to magnify the effect of limited provider competition on the individual market.

On (2), the obvious answer seems is addressing monopoly power in the healthcare provider market through the Federal Trade Commission (FTC), which in practice would be legislation allowing the FTC to enforce all anti-trust laws with respect to nonprofit healthcare firms. Under the Federal Trade Commission Act, Section 4, the FTC is not allowed to enforce many of its laws due to these firms' nonprofit status. Resolving this is essential in addressing the horizontal consolidation observed in this paper, as roughly 60\% of short term general care hospitals are non-profits. 

However, as \citet{berenson_addressing_2015} notes, this approach would do nothing to address the exercise of unreasonable market power by existing monopolies. With this in mind, some form of rate setting in counties with highly concentrated healthcare provider markets may be needed. One approach was implemented statewide in Maryland in 2014; the state set standard reimbursement costs for medical procedures for all payers (i.e. "all-payer rate setting"). Preliminary results are mixed, but some researchers point to it as a great success, as costs were contained and quality of care improved in many areas \citep{rajkumar_marylands_2014}. \citet{berenson_addressing_2015} recommends a more relaxed version of rate-setting, in which price ceilings are placed on the rates negotiated between insurers and providers, set as a percentage above the Medicare yardstick.

On (3), in the many rural counties where concentrated healthcare provider markets are not the result of consolidation but scarcity, expanding Medicaid (if their state has not already done so, as many across the South haven't) would be a huge support. As shown in \citet{blavin_medicaid_2021}, hospitals in states with the Medicaid expansion have significantly higher Medicaid payment rates and significantly lower uncompensated care costs, and are at much lower risk of closure as a result.

Beyond this though, it is high time to consider direct government intervention in ACA exchanges through a public option. As \citet{fiedler_capping_2020} observes, a public option would both reduce provider prices and address lack of choice/competition in ACA exchanges (assuming it sets reimbursement rates at some percentage of the prices Medicare pays providers). While it is less flexible than other tools targeted at reducing provider prices (i.e. the downward pressure on provider prices resulting from a public option would be universal, not targeted at specific high-cost services) this dual impact makes it uniquely qualified to address the problems laid out in this paper. Public option reimbursement rates would reduce provider leverage during negotiations with insurers: since private plans will have to compete with the public option, they will not be willing to accept reimbursement rates significantly higher than those set by the public option, and providers would recognize that if an insurer walked away from the bargaining table their potential enrollees would likely be captured by the public option, meaning the provider would have to accept the public option reimbursement rates regardless. This reduced leverage should make ACA exchanges in counties with highly concentrated healthcare provider markets more attractive to insurers. Moreover, the very existence of the public option gives consumers on ACA exchanges an additional choice for insurance.

While direct government entry to ACA exchanges may seem like an extreme step, it's worth reflecting on how dependent these exchanges already are on the federal government. Not only are most exchanges managed by the Department of Health and Human Services (HHS), all exchanges are dependent on cost-sharing subsidies; in other words, the individual market is already propped up by federal dollars. With this in mind, preventing federal entry to exchanges through a public option on the grounds of government over-step seems inane. 

\section{Directions for Future Work}

The most immediate extension of this work is to retest my main model with a more general measure of healthcare competition (one that would have to account for horizontal and vertical consolidation, as in \citet{scheffler_consolidation_2018}). Another obvious extension would be altering my main model to control for all time invariant differences, i.e. a fixed effects regression on panel data. Unfortunately, this extension is impossible for the next few years: there are currently not enough years of marketplace data to be used in such an analysis. 

Another extension, which researchers wouldn't have to wait a decade for, would be to consider the relationship between provider competition and competition in the Medicaid Managed Care market. Managed Care Organizations (MCOs) are private companies which contract with states to deliver Medicaid benefits. Currently 39 states (and DC) use MCOs to administer Medicaid benefits. Only 30 states publicly share enrollment data, but in those 30 alone there are 48 million enrollees, three times as many as are in the entire individual market. Thus, investigating whether falling competition amongst healthcare providers poses the same risk to the Medicaid MCO market as it does to ACA exchanges would be an extremely worthwhile endeavor. 

\section*{Conclusion}
As outlined in the introduction, the motivation for this paper was to confirm the conclusions drawn by earlier field research \citep{morrisey_five-state_2017}, that competition among healthcare providers is essential for robust and competitive ACA exchanges. In doing so, I contribute to the existing literature with my findings and by (1) illustrating how rating areas offer researchers a powerful tool for model specification when studying ACA exchanges, and (2) outlining a novel approach to hospital market HHI construction using hospital "radii", instead of generalizing results across counties using rating area boundaries as past work has done. 

In closing, it's worth reflecting on the importance of ACA exchanges. As mentioned in my introduction, these markets cover only a small fraction of health insurance enrollees nationwide. And while the market conditions faced by 9 million consumers every year are certainly worth studying in their own right, it would be foolish to ignore that the significance of competition and premiums on ACA exchanges are often exaggerated for political purposes.

That said, some of the out-sized importance attached ACA exchanges is deserved. Regardless of their characterization, ACA exchanges are a market based solution to healthcare in the United States. Their goal is to provide consumers with low cost choices for health insurance, without the unscrupulous practices notorious in the pre-ACA individual market. Whether ACA exchanges are able to achieve this goal, and what role the federal government ends up playing in their administration, may be indicative of the evolution of public private partnership in US healthcare.

\pagebreak

\bibliographystyle{chicago}  
\bibliography{aca_bib}

\pagebreak

\appendix
\counterwithin{figure}{section}
\counterwithin{table}{section}
\section{Appendix}
\subsection{Herfindahl-Hirschman index (HHI) calculations}
Insurer HHI was calculated using the issuer-level enrollment data publicly available from the Center for Medicare and Medicaid Services. The data provided the number of purchases of a given issuer in a given county; counties with less than ten purchases were withheld from the data. I calculated market share for each issuer in each rating area, and then squared and summed the result.

I used a similar process for hospital HHI, using data on short-term general hospital admissions from the American Hospital Association (AHA). Instead of using county boundaries to determine market boundaries, I constructed radii around each of my hospitals in line with the findings of \citet{gresenz_updated_2004}. Their work measured the "90\% boundary" for a large sample of rural and urban hospitals, i.e. the boundary within which 90\% of a hospitals admitted patients lived (rural vs. urban distinction is based on whether the county is in a Metropolitan Statistical Area, i.e. a MSA). They find the mean value of this statistic is 10.4 miles for urban hospitals, with a standard deviation of 8.5 miles, versus 14.2 for rural hospitals, with a standard deviation of 14.6. 

The AHA data allows me to determine whether or not a hospital is in a MSA, and therefore I am able to match it to the corresponding mean and standard deviation from \citet{gresenz_updated_2004}. I use $\bar{x} + 2s_x$ for the radii of the hospital HHI used in the paper (i.e. 27.4 miles for urban hospitals, 43.4 miles for rural hospitals), and count a hospital as part of a county's market if its circle overlaps the centroid of the county. I counted hospitals under the same health system as one firm. I geocoded the AHA data using \citet{kahle_ggmap_2013}, and found the centroid of the counties in my data using \citet{bivand_rgeos_2020}. 

Heat maps with my calculations for insurer and hospital HHI can be seen on the following pages. Grayed out sections reflect counties with withheld data. I also re-fit my model using hospital HHI's calculated with radii one standard deviation lower and higher than my chosen value, as a robustness check; tables with those results can also be seen below. 

\pagebreak
\newgeometry{left=1cm, right=1cm}
\begin{figure}[!h]
\begin{center}
\includegraphics[height=3.5in,angle=0]{insurerHHI_2015.png}
\caption{Insurer HHI Heat Map, 2015}\label{Figure 5}
\vspace{5mm}
\includegraphics[height=3.5in,angle=0]{insurerHHi_2016.png}
\caption{Insurer HHI Heat Map, 2016}\label{Figure 6}
\end{center}
\end{figure}

\pagebreak
\begin{figure}[!h]
\begin{center}
\includegraphics[height=3.5in,angle=0]{hospitalHHI_2014.png}
\caption{Hospital HHI Heat Map, 2014}\label{Figure 7}
\vspace{5mm}
\includegraphics[height=3.5in,angle=0]{hospitalHHI_2015.png}
\caption{Hospital HHI Heat Map, 2015}\label{Figure 8}
\end{center}
\end{figure}
\restoregeometry

\begin{table}
\centering
\caption{Main results (hospital market radius one SD lower)}
\input{./tables/main_results_1}
\end{table}

\begin{table}
\centering
\caption{Main results (hospital market radius one SD higher)}
\input{./tables/main_results_2}
\end{table}

\clearpage

\subsection{Non-normality of model residuals}
My main model's residuals fail the Shapiro-Wilk's test of normality, due seemingly to outlier values at the tails of my dependent variable distribution. This doesn't undermine the properties of my coefficient of interest estimate (i.e. OLS remains BLUE), but it does call into question my standard errors and p-values. Because I already log-linearize my dependent variable for interpretation purposes, winsorizing is an ineffective option. Instead, I bootstrap my regression, following the procedure outlined by \citet{fox_bootstrapping_2017}. The 99\% confidence interval around my empirical distribution for my coefficient of interest is (.013, .071), which is about in line with what one would expect from my cluster-robust standard errors (i.e. I again reject the null hypothesis at significance $p<.01$). Graphs of my model residuals, as well as my bootstrapped coefficient distribution, can be found below.

\begin{figure}[!h]
\begin{center}
\includegraphics[height=4in,angle=0]{hist_resid_mainmodel.png}
\caption{Histogram of residuals (main model)}
\end{center}
\end{figure}
\begin{figure}[!h]
\begin{center}
\includegraphics[height=4in,angle=0]{qq_mainmodel.png}
\caption{Q-Q plot of residuals (main model)}
\end{center}
\end{figure}
\begin{figure}[!h]
\begin{center}
\includegraphics[height=4in,angle=0]{bootstrap_coef.png}
\caption{Histogram of bootstrapped coefficient (main model)}
\end{center}
\end{figure}


\end{document}